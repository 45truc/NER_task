{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f89805d-f36b-46b7-baa9-bf2e43415ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import scipy\n",
    "import numpy as np\n",
    "import os,sys\n",
    "\n",
    "# for windows\n",
    "'''\n",
    "currentdir = Path.cwd()\n",
    "sys.path.insert(0,str(currentdir)+'\\\\utils') \n",
    "'''\n",
    "\n",
    "# for ubuntu\n",
    "os.chdir('./utils')\n",
    "import skseq\n",
    "import skseq.sequences.structured_perceptron as spc\n",
    "from utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d32a652",
   "metadata": {},
   "source": [
    "This notebook loads the data, loads the fitted models from disk and evaluates the models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eaf16f2c",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03595663",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = NerCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b3c676-377c-41f0-a956-042ce13405c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "\n",
    "#data_path = parentdir + data_path\n",
    "\n",
    "train_seq = corpus.read_sequence_list(data_path + \"/train_data_ner.csv\", \n",
    "                                            max_sent_len=100)\n",
    "\n",
    "test_seq = corpus.read_sequence_list(data_path + \"/test_data_ner.csv\",\n",
    "                                           max_sent_len=100)\n",
    "\n",
    "tiny_test_seq = corpus.read_sequence_list(data_path + \"/tiny_test.csv\", \n",
    "                                          max_sent_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828cca92-fc81-4dd8-99d9-73cac8a67f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_test_metrics = {'Accuracy':[],'F1':[]}\n",
    "names = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0bbeb7e",
   "metadata": {},
   "source": [
    "## Structure Perceptron"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1430a851",
   "metadata": {},
   "source": [
    "### Structure Perceptron w/ given features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c30ec6-3714-4317-8253-3d5189e7cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()\n",
    "\n",
    "sp = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "sp.load_model(dir=\"../fitted_models/perceptron_5_iter_given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf609ed-f838-408e-9d85-b0aa27d45b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_train = sp.viterbi_decode_corpus(train_seq)\n",
    "#pred_test  = sp.viterbi_decode_corpus(test_seq)\n",
    "pred_tiny_test  = sp.viterbi_decode_corpus(tiny_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e2c838-384a-4528-b6a9-6f927ea3f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, f1 = Evaluate_metrics(tiny_test_seq.seq_list, pred_tiny_test, corpus)\n",
    "tiny_test_metrics['Accuracy'].append(acc)\n",
    "tiny_test_metrics['F1'].append(f1)\n",
    "names.append('SP-given')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7f92d88",
   "metadata": {},
   "source": [
    "### Structure Perceptron w/ extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5f3cf-d42c-43c0-8941-131e13059f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skseq.sequences.extended_features import *\n",
    "\n",
    "feature_mapper_ext = Extended_Features(train_seq)\n",
    "feature_mapper_ext.build_features()\n",
    "\n",
    "sp = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper_ext)\n",
    "sp.load_model(dir=\"./fitted_models/perceptron_5_iter_extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544166ef-65dc-4dec-ae98-729554d8cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tiny_test  = sp.viterbi_decode_corpus(tiny_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcada7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, f1 = Evaluate_metrics(tiny_test_seq.seq_list, pred_tiny_test, corpus)\n",
    "tiny_test_metrics['Accuracy'].append(acc)\n",
    "tiny_test_metrics['F1'].append(f1)\n",
    "names.append('SP-extra')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f294a7e9",
   "metadata": {},
   "source": [
    "## Deep Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec99fb3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
